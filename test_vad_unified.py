#!/usr/bin/env python3
"""
ç»Ÿä¸€VADæ¨¡å—æµ‹è¯•
æµ‹è¯•æ–°çš„VADProcessorç±»çš„åŠŸèƒ½
"""

import asyncio
import numpy as np
import time
import tempfile
import soundfile as sf
from pathlib import Path

from app.core.vad import VADProcessor, VADConfig, get_vad_processor
from app.config import settings

async def test_vad_config():
    """æµ‹è¯•VADé…ç½®"""
    print("=== VADé…ç½®æµ‹è¯• ===")
    
    # æµ‹è¯•é»˜è®¤é…ç½®
    try:
        config = VADConfig()
        print("âœ… é»˜è®¤é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"   - æ¨¡å‹è·¯å¾„: {config.model_path}")
        print(f"   - é˜ˆå€¼: {config.threshold}")
        print(f"   - æœ€å°é™éŸ³æ—¶é•¿: {config.min_silence_duration}")
        print(f"   - æœ€å°è¯­éŸ³æ—¶é•¿: {config.min_speech_duration}")
        print(f"   - æœ€å¤§è¯­éŸ³æ—¶é•¿: {config.max_speech_duration}")
    except Exception as e:
        print(f"âŒ é»˜è®¤é…ç½®åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•é…ç½®éªŒè¯
    try:
        invalid_config = VADConfig(threshold=1.5)  # æ— æ•ˆé˜ˆå€¼
        print("âŒ é…ç½®éªŒè¯å¤±è´¥ - åº”è¯¥æŠ›å‡ºå¼‚å¸¸")
        return False
    except ValueError:
        print("âœ… é…ç½®éªŒè¯æ­£å¸¸å·¥ä½œ")
    
    # æµ‹è¯•é…ç½®æ›´æ–°
    try:
        config.update(threshold=0.6, min_speech_duration=0.3)
        print("âœ… é…ç½®æ›´æ–°æˆåŠŸ")
        print(f"   - æ–°é˜ˆå€¼: {config.threshold}")
        print(f"   - æ–°æœ€å°è¯­éŸ³æ—¶é•¿: {config.min_speech_duration}")
    except Exception as e:
        print(f"âŒ é…ç½®æ›´æ–°å¤±è´¥: {e}")
        return False
    
    return True

async def test_vad_processor_basic():
    """æµ‹è¯•VADå¤„ç†å™¨åŸºæœ¬åŠŸèƒ½"""
    print("\n=== VADå¤„ç†å™¨åŸºæœ¬åŠŸèƒ½æµ‹è¯• ===")
    
    # åˆ›å»ºVADå¤„ç†å™¨
    try:
        processor = VADProcessor()
        print("âœ… VADå¤„ç†å™¨åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ VADå¤„ç†å™¨åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    try:
        success = await processor.initialize()
        if success:
            print("âœ… VADå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âŒ VADå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥")
            return False
    except Exception as e:
        print(f"âŒ VADå¤„ç†å™¨åˆå§‹åŒ–å¼‚å¸¸: {e}")
        return False
    
    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ•°æ®
    sample_rate = 16000
    duration = 3.0  # 3ç§’
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # ç”ŸæˆåŒ…å«è¯­éŸ³å’Œé™éŸ³çš„éŸ³é¢‘ä¿¡å·
    audio_data = np.zeros_like(t, dtype=np.float32)
    
    # æ·»åŠ å‡ ä¸ªè¯­éŸ³æ®µè½ï¼ˆæ­£å¼¦æ³¢æ¨¡æ‹Ÿï¼‰
    # æ®µè½1: 0.5-1.5ç§’
    mask1 = (t >= 0.5) & (t <= 1.5)
    audio_data[mask1] = 0.3 * np.sin(2 * np.pi * 440 * t[mask1])  # 440HzéŸ³è°ƒ
    
    # æ®µè½2: 2.0-2.8ç§’
    mask2 = (t >= 2.0) & (t <= 2.8)
    audio_data[mask2] = 0.3 * np.sin(2 * np.pi * 880 * t[mask2])  # 880HzéŸ³è°ƒ
    
    print(f"åˆ›å»ºäº† {duration}ç§’ çš„æµ‹è¯•éŸ³é¢‘ï¼ŒåŒ…å«2ä¸ªè¯­éŸ³æ®µè½")
    
    # æµ‹è¯•è¯­éŸ³æ£€æµ‹
    try:
        start_time = time.time()
        segments = await processor.detect_speech_segments(audio_data, sample_rate)
        processing_time = time.time() - start_time
        
        print(f"âœ… è¯­éŸ³æ£€æµ‹å®Œæˆï¼Œè€—æ—¶: {processing_time:.3f}ç§’")
        print(f"   - æ£€æµ‹åˆ° {len(segments)} ä¸ªè¯­éŸ³æ®µè½")
        
        for i, segment in enumerate(segments):
            print(f"   - æ®µè½ {i+1}: {segment.start:.2f}s - {segment.end:.2f}s "
                  f"(æ—¶é•¿: {segment.duration:.2f}s, ç½®ä¿¡åº¦: {segment.confidence})")
        
        if len(segments) > 0:
            print("âœ… è¯­éŸ³æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³æ®µè½ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´VADå‚æ•°")
    
    except Exception as e:
        print(f"âŒ è¯­éŸ³æ£€æµ‹å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    try:
        stats = processor.get_stats()
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
        print(f"   - å¤„ç†æ€»æ—¶é•¿: {stats['total_processed_duration']:.2f}ç§’")
        print(f"   - è¯­éŸ³æ€»æ—¶é•¿: {stats['total_speech_duration']:.2f}ç§’")
        print(f"   - è¯­éŸ³æ¯”ä¾‹: {stats['speech_ratio']:.2%}")
        print(f"   - å¹³å‡å¤„ç†æ—¶é—´: {stats['average_processing_time']:.3f}ç§’")
        print(f"   - æ¨¡å‹åŠ è½½æ—¶é—´: {stats['model_load_time']:.2f}ç§’")
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡ä¿¡æ¯è·å–å¤±è´¥: {e}")
    
    # å…³é—­å¤„ç†å™¨
    await processor.close()
    print("âœ… VADå¤„ç†å™¨å·²å…³é—­")
    
    return True

async def test_streaming_vad():
    """æµ‹è¯•æµå¼VADå¤„ç†"""
    print("\n=== æµå¼VADå¤„ç†æµ‹è¯• ===")
    
    processor = VADProcessor()
    await processor.initialize()
    
    sample_rate = 16000
    chunk_duration = 0.5  # æ¯å—0.5ç§’
    chunk_size = int(sample_rate * chunk_duration)
    total_chunks = 6  # æ€»å…±3ç§’
    
    print(f"æ¨¡æ‹Ÿæµå¼éŸ³é¢‘å¤„ç†ï¼Œæ¯å— {chunk_duration}ç§’ï¼Œå…± {total_chunks} å—")
    
    all_segments = []
    
    for i in range(total_chunks):
        # ç”ŸæˆéŸ³é¢‘å—
        t_start = i * chunk_duration
        t_end = (i + 1) * chunk_duration
        t = np.linspace(t_start, t_end, chunk_size)
        
        # åœ¨æŸäº›å—ä¸­æ·»åŠ è¯­éŸ³ä¿¡å·
        if 1 <= i <= 3:  # ç¬¬2-4å—åŒ…å«è¯­éŸ³
            audio_chunk = 0.3 * np.sin(2 * np.pi * 440 * t).astype(np.float32)
        else:
            audio_chunk = np.zeros(chunk_size, dtype=np.float32)
        
        # å¤„ç†éŸ³é¢‘å—
        try:
            segments = await processor.process_streaming_audio(audio_chunk, sample_rate)
            all_segments.extend(segments)
            
            if segments:
                print(f"   å— {i+1}: æ£€æµ‹åˆ° {len(segments)} ä¸ªè¯­éŸ³æ®µè½")
            else:
                print(f"   å— {i+1}: æœªæ£€æµ‹åˆ°è¯­éŸ³")
                
        except Exception as e:
            print(f"âŒ æµå¼å¤„ç†å¤±è´¥ (å— {i+1}): {e}")
            await processor.close()
            return False
    
    print(f"âœ… æµå¼å¤„ç†å®Œæˆï¼Œæ€»å…±æ£€æµ‹åˆ° {len(all_segments)} ä¸ªè¯­éŸ³æ®µè½")
    
    await processor.close()
    return True

async def test_global_vad_processor():
    """æµ‹è¯•å…¨å±€VADå¤„ç†å™¨"""
    print("\n=== å…¨å±€VADå¤„ç†å™¨æµ‹è¯• ===")
    
    try:
        # è·å–å…¨å±€å¤„ç†å™¨
        processor1 = await get_vad_processor()
        processor2 = await get_vad_processor()
        
        # åº”è¯¥æ˜¯åŒä¸€ä¸ªå®ä¾‹
        if processor1 is processor2:
            print("âœ… å…¨å±€VADå¤„ç†å™¨å•ä¾‹æ¨¡å¼æ­£å¸¸")
        else:
            print("âŒ å…¨å±€VADå¤„ç†å™¨å•ä¾‹æ¨¡å¼å¤±è´¥")
            return False
        
        # æµ‹è¯•é…ç½®æ›´æ–°
        success = processor1.configure(threshold=0.6)
        if success:
            print("âœ… å…¨å±€å¤„ç†å™¨é…ç½®æ›´æ–°æˆåŠŸ")
        else:
            print("âŒ å…¨å±€å¤„ç†å™¨é…ç½®æ›´æ–°å¤±è´¥")
    
    except Exception as e:
        print(f"âŒ å…¨å±€VADå¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

async def test_vad_performance():
    """æµ‹è¯•VADæ€§èƒ½"""
    print("\n=== VADæ€§èƒ½æµ‹è¯• ===")
    
    processor = VADProcessor()
    await processor.initialize()
    
    # åˆ›å»ºè¾ƒé•¿çš„æµ‹è¯•éŸ³é¢‘ï¼ˆ10ç§’ï¼‰
    sample_rate = 16000
    duration = 10.0
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # ç”Ÿæˆå¤æ‚çš„éŸ³é¢‘ä¿¡å·
    audio_data = np.zeros_like(t, dtype=np.float32)
    
    # æ·»åŠ å¤šä¸ªè¯­éŸ³æ®µè½
    speech_intervals = [(1, 2.5), (3, 4), (5.5, 7), (8, 9.5)]
    for start, end in speech_intervals:
        mask = (t >= start) & (t <= end)
        frequency = 440 + (start * 100)  # ä¸åŒé¢‘ç‡
        audio_data[mask] = 0.3 * np.sin(2 * np.pi * frequency * t[mask])
    
    print(f"åˆ›å»ºäº† {duration}ç§’ çš„å¤æ‚éŸ³é¢‘ï¼ŒåŒ…å« {len(speech_intervals)} ä¸ªè¯­éŸ³æ®µè½")
    
    # æ€§èƒ½æµ‹è¯•
    num_runs = 5
    processing_times = []
    
    for i in range(num_runs):
        start_time = time.time()
        segments = await processor.detect_speech_segments(audio_data, sample_rate)
        processing_time = time.time() - start_time
        processing_times.append(processing_time)
        
        print(f"   è¿è¡Œ {i+1}: {processing_time:.3f}ç§’, æ£€æµ‹åˆ° {len(segments)} ä¸ªæ®µè½")
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    avg_time = np.mean(processing_times)
    std_time = np.std(processing_times)
    min_time = np.min(processing_times)
    max_time = np.max(processing_times)
    
    real_time_factor = duration / avg_time
    
    print(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ:")
    print(f"   - å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f} Â± {std_time:.3f}ç§’")
    print(f"   - æœ€å¿«/æœ€æ…¢: {min_time:.3f}/{max_time:.3f}ç§’")
    print(f"   - å®æ—¶å€æ•°: {real_time_factor:.1f}x")
    
    if real_time_factor > 1:
        print(f"âœ… å¤„ç†é€Ÿåº¦è¶…è¿‡å®æ—¶ ({real_time_factor:.1f}å€)")
    else:
        print(f"âš ï¸ å¤„ç†é€Ÿåº¦ä½äºå®æ—¶ ({real_time_factor:.1f}å€)")
    
    # è·å–æœ€ç»ˆç»Ÿè®¡
    stats = processor.get_stats()
    print(f"   - æ€»å¤„ç†æ—¶é•¿: {stats['total_processed_duration']:.1f}ç§’")
    print(f"   - æ€»è¯­éŸ³æ—¶é•¿: {stats['total_speech_duration']:.1f}ç§’")
    print(f"   - é”™è¯¯æ¬¡æ•°: {stats['error_count']}")
    
    await processor.close()
    return True

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ç»Ÿä¸€VADæ¨¡å—æµ‹è¯•...")
    print(f"VADæ¨¡å‹è·¯å¾„: {settings.VAD_MODEL_PATH}")
    print(f"æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {Path(settings.VAD_MODEL_PATH).exists()}")
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_results.append(await test_vad_config())
    test_results.append(await test_vad_processor_basic())
    test_results.append(await test_streaming_vad())
    test_results.append(await test_global_vad_processor())
    test_results.append(await test_vad_performance())
    
    # æ€»ç»“
    passed = sum(test_results)
    total = len(test_results)
    
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"é€šè¿‡: {passed}/{total} é¡¹æµ‹è¯•")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰VADæ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"âŒ {total - passed} é¡¹æµ‹è¯•å¤±è´¥")
    
    return passed == total

if __name__ == "__main__":
    asyncio.run(main())
